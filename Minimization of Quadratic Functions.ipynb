{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimization of Quadratic Functions\n",
    "\n",
    "A good first example is the minimization of quadratic functions. This will be useful in more general situations since we'll often form a quadratic approximation of the objective function. We'll study a quadratic function that takes the following form\n",
    "\n",
    "\\begin{equation*}\n",
    "    f(x) = \\frac{1}{2} x^{T} A x + b^{T} x + c,\n",
    "\\end{equation*}\n",
    "\n",
    "where $x \\in \\mathbb{R}^{n}$, $A = A^{T} \\in \\mathbb{R}^{n \\times n}$. Since $A$ is symmetric, it has an eigenvalue decomposition $A = Q \\Lambda Q$. \n",
    "\n",
    "To analyze $f(x)$, it is convenient to use a change of basis to use an eigenvector basis as follows \n",
    "\n",
    "\\begin{equation*}\n",
    "    x = Q \\xi,\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\xi \\in \\mathbb{R}^{n}$ are the components along each eigenvector. For each $\\xi$ point, we can recover the original point $x = Q \\xi$.\n",
    "\n",
    "The advantage of this new basis is that it leads to a simplified form for the quadratic as follows\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "  f(\\xi) & = \\frac{1}{2} \\xi^{T} Q^{T} A Q \\xi + \\xi^{T} Q^{T} b + c = \n",
    "  \\frac{1}{2} \\xi^{T} \\Lambda \\xi + \\xi^{T} \\bar{b} + c \\\\\n",
    "  &= \\sum_{i=1}^{n} (\\lambda_{i} \\xi_{i}^2 + \\bar{b}_{i} \\xi_{i} ) + c\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "where we have defined $\\bar{b} = Q^{T} b$ or component-wise $\\bar{b}_{i} = q_{i}^{T}b$. This is a *separable function* because it can be written as\n",
    "\n",
    "\\begin{equation*}\n",
    "    f(\\xi) = \\sum_{i=1}^{n} f_{i}(\\xi_{i})\n",
    "\\end{equation*}\n",
    "\n",
    "so that we can minimize each $f_{i}(\\xi_{i})$ independently since each of these functions share no common variables. Focusing on a single function, $f_{i}(\\xi_{i})$ we have the form\n",
    "\n",
    "\\begin{equation*}\n",
    "    f_{i}(\\xi_{i}) = \\frac{1}{2} \\lambda_{i} \\xi_{i}^{2} + \\bar{b}_{i} \\xi_{i}\n",
    "\\end{equation*}\n",
    "\n",
    "(We ignore the constant term because it has no impact on the location or characterization of the minimizer.)\n",
    "\n",
    "Based on minimization of a one-dimensional function, we can make progress by considering a number of different cases. First, if $\\lambda_{i} = 0$ and $\\bar{b}_{i} = 0$, then the function is constant and any $\\xi_{i}$ we pick is a minimizer or maximizer! If $\\lambda_{i} = 0$ and $\\bar{b}_{i} \\ne 0$, then the function is a line and there is no minimizer or maximizer.\n",
    "\n",
    "Now, if $\\lambda_{i} \\ne 0$, we have a quadratic function. Taking the derivative of $f_{i}(\\xi_{i})$ and set it equal to zero to obtain the critical point gives\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\xi_{i}^{cr} = -\\frac{\\bar{b}_{i}}{\\lambda_{i}}\n",
    "\\end{equation*}\n",
    "\n",
    "Finding the second derivative of $f_{i}(\\xi_{i})$ gives just $\\lambda_{i}$. So if $\\lambda_{i} \\ne = 0$, then when $\\lambda_{i} > 0$, we have a minimizer at $\\xi_{i}^{*} = - {\\bar{b}_{i}}/{\\lambda_{i}}$. Whereas if $\\lambda_{i} < 0$, we have a maximizer at $\\xi_{i} = {\\bar{b}_{i}}/{\\lambda_{i}}$.\n",
    "\n",
    "As a result we have the following cases:\n",
    "\n",
    "1. If $\\lambda_{i} > 0$, then $\\xi_{i}^{*}$ is a minimizer\n",
    "2. If $\\lambda_{i} > 0$, then $\\xi_{i}^{*}$ is a maximizer\n",
    "3. If $\\lambda_{i} = 0$ and $\\bar{b}_{i} = 0$, then any value of $\\xi_{i}$ is a minimizer or maximizer\n",
    "4. If $\\lambda_{i} = 0$ and $\\bar{b}_{i} \\ne 0$, then the function is unbounded from below (no minimizer)\n",
    "\n",
    "We can now apply these conditions to all the eigenvectors.\n",
    "\n",
    "1. If $A$ is positive definite, then all $\\xi_{i}$ directions are minimizers\n",
    "2. If $A$ is positive semi-definite, then the function is either unbounded from below or has a non-unique minimizer depending on $b$\n",
    "3. If $A$ is indefinite, negative semi-definite or negative definite, then the function is unbounded from below and has no minimizer\n",
    "\n",
    "For case 1, we have that the location of the minimizer is given by\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\xi^{*} = -\\Lambda^{-1}\\bar{b} = -\\Lambda^{-1} Q^{T} b\n",
    "\\end{equation*}\n",
    "\n",
    "Transforming this back into the design coordinates gives\n",
    "\n",
    "\\begin{equation*}\n",
    "    x^{*} = -Q \\xi^{*} = -Q \\Lambda^{-1} Q^{T} b = -A^{-1} b\n",
    "\\end{equation*}\n",
    "\n",
    "Note that $x^{*} = -A^{-1} b$ is a minimizer *only if $A$ is positive definite!*\n",
    "\n",
    "For case 2, we have that $\\lambda_{i} \\ge 0$. For those $\\lambda_{i} = 0$, we have to test the conditions on $\\bar{b}_{i} = q_{i}^{T} b$. So if $q_{i}^{T} b = 0$ for each $i$ where we have $\\lambda_{i} = 0$, then we have a non-unique minimizer, because we can move along $\\xi_{i}$ without changing the function value.\n",
    "\n",
    "Note that for case 2, the matrix $A$ is singular, so we have to be careful!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
